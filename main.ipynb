{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed file found and loaded.\n",
      "Dataframe shape: (22961, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/seby/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/seby/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>company_names</th>\n",
       "      <th>url</th>\n",
       "      <th>verified</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>Price Day Before Tweet</th>\n",
       "      <th>Price Day of Tweet</th>\n",
       "      <th>Price Day After Tweet</th>\n",
       "      <th>tweet_polarity</th>\n",
       "      <th>tweet_subjectivity</th>\n",
       "      <th>preprocessed_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1019696670777503700</td>\n",
       "      <td>VIDEO: “I was in my office. I was minding my own business...” –David Solomon tells $GS interns how he learned he wa… https://t.co/QClAITywXV</td>\n",
       "      <td>2018-07-18 21:33:26</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>GS</td>\n",
       "      <td>The Goldman Sachs</td>\n",
       "      <td>https://twitter.com/i/web/status/1019696670777503745</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>202.197433</td>\n",
       "      <td>202.389984</td>\n",
       "      <td>200.980820</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>['video', 'office', 'minding', 'business', '–david', 'solomon', 'tell', '$GS', 'intern', 'learned', 'wa…', 'https://t.co/QClAITywXV']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1019709091038548000</td>\n",
       "      <td>The price of lumber $LB_F is down 22% since hitting its YTD highs. The Macy's $M turnaround is still happening.… https://t.co/XnKsV4De39</td>\n",
       "      <td>2018-07-18 22:22:47</td>\n",
       "      <td>StockTwits</td>\n",
       "      <td>M</td>\n",
       "      <td>Macy's</td>\n",
       "      <td>https://twitter.com/i/web/status/1019709091038547968</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>29.254162</td>\n",
       "      <td>29.751339</td>\n",
       "      <td>30.745678</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>['price', 'lumber', '$LB_F', '22', 'since', 'hitting', 'ytd', 'high', 'macy', '$M', 'turnaround', 'still', 'https://t.co/XnKsV4De39']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1019711413798035500</td>\n",
       "      <td>Who says the American Dream is dead? https://t.co/CRgx19x7sA</td>\n",
       "      <td>2018-07-18 22:32:01</td>\n",
       "      <td>TheStreet</td>\n",
       "      <td>AIG</td>\n",
       "      <td>American</td>\n",
       "      <td>https://buff.ly/2L3kmc4</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>46.698963</td>\n",
       "      <td>47.057472</td>\n",
       "      <td>45.964901</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>['say', 'american', 'dream', 'dead', 'https://t.co/CRgx19x7sA']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1019718460287389700</td>\n",
       "      <td>How satellites avoid attacks and space junk while circling the Earth https://t.co/aHzIV3Lqp5 #paid @Oracle https://t.co/kacpqZWiDJ</td>\n",
       "      <td>2018-07-18 23:00:01</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>http://on.forbes.com/6013DqDDU</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>44.699883</td>\n",
       "      <td>44.462223</td>\n",
       "      <td>44.279408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['satellite', 'avoid', 'attack', 'space', 'junk', 'circling', 'earth', 'https://t.co/aHzIV3Lqp5', 'paid', '@Oracle', 'https://t.co/kacpqZWiDJ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1019720723441635300</td>\n",
       "      <td>Senate wants emergency alerts to go out through Netflix Spotify etc. https://t.co/23yy3whBlc by @grg</td>\n",
       "      <td>2018-07-18 23:09:00</td>\n",
       "      <td>TechCrunch</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>https://tcrn.ch/2L8DsgT</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>379.480011</td>\n",
       "      <td>375.130005</td>\n",
       "      <td>364.230011</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>['senate', 'want', 'emergency', 'alert', 'go', 'netflix', 'spotify', 'etc', 'https://t.co/23yy3whBlc', '@grg']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  \\\n",
       "0  1019696670777503700   \n",
       "1  1019709091038548000   \n",
       "2  1019711413798035500   \n",
       "3  1019718460287389700   \n",
       "4  1019720723441635300   \n",
       "\n",
       "                                                                                                                                           text  \\\n",
       "0  VIDEO: “I was in my office. I was minding my own business...” –David Solomon tells $GS interns how he learned he wa… https://t.co/QClAITywXV   \n",
       "1      The price of lumber $LB_F is down 22% since hitting its YTD highs. The Macy's $M turnaround is still happening.… https://t.co/XnKsV4De39   \n",
       "2                                                                                  Who says the American Dream is dead? https://t.co/CRgx19x7sA   \n",
       "3            How satellites avoid attacks and space junk while circling the Earth https://t.co/aHzIV3Lqp5 #paid @Oracle https://t.co/kacpqZWiDJ   \n",
       "4                                          Senate wants emergency alerts to go out through Netflix Spotify etc. https://t.co/23yy3whBlc by @grg   \n",
       "\n",
       "             timestamp        source symbols      company_names  \\\n",
       "0  2018-07-18 21:33:26  GoldmanSachs      GS  The Goldman Sachs   \n",
       "1  2018-07-18 22:22:47    StockTwits       M             Macy's   \n",
       "2  2018-07-18 22:32:01     TheStreet     AIG           American   \n",
       "3  2018-07-18 23:00:01        Forbes    ORCL             Oracle   \n",
       "4  2018-07-18 23:09:00    TechCrunch    NFLX            Netflix   \n",
       "\n",
       "                                                    url  verified  month  day  \\\n",
       "0  https://twitter.com/i/web/status/1019696670777503745      True      7   18   \n",
       "1  https://twitter.com/i/web/status/1019709091038547968      True      7   18   \n",
       "2                               https://buff.ly/2L3kmc4      True      7   18   \n",
       "3                        http://on.forbes.com/6013DqDDU      True      7   18   \n",
       "4                               https://tcrn.ch/2L8DsgT      True      7   18   \n",
       "\n",
       "   year  Price Day Before Tweet  Price Day of Tweet  Price Day After Tweet  \\\n",
       "0  2018              202.197433          202.389984             200.980820   \n",
       "1  2018               29.254162           29.751339              30.745678   \n",
       "2  2018               46.698963           47.057472              45.964901   \n",
       "3  2018               44.699883           44.462223              44.279408   \n",
       "4  2018              379.480011          375.130005             364.230011   \n",
       "\n",
       "   tweet_polarity  tweet_subjectivity  \\\n",
       "0        0.600000            1.000000   \n",
       "1       -0.155556            0.288889   \n",
       "2       -0.100000            0.200000   \n",
       "3        0.000000            0.000000   \n",
       "4        0.200000            0.100000   \n",
       "\n",
       "                                                                                                                                preprocessed_tweet  \n",
       "0            ['video', 'office', 'minding', 'business', '–david', 'solomon', 'tell', '$GS', 'intern', 'learned', 'wa…', 'https://t.co/QClAITywXV']  \n",
       "1            ['price', 'lumber', '$LB_F', '22', 'since', 'hitting', 'ytd', 'high', 'macy', '$M', 'turnaround', 'still', 'https://t.co/XnKsV4De39']  \n",
       "2                                                                                  ['say', 'american', 'dream', 'dead', 'https://t.co/CRgx19x7sA']  \n",
       "3  ['satellite', 'avoid', 'attack', 'space', 'junk', 'circling', 'earth', 'https://t.co/aHzIV3Lqp5', 'paid', '@Oracle', 'https://t.co/kacpqZWiDJ']  \n",
       "4                                   ['senate', 'want', 'emergency', 'alert', 'go', 'netflix', 'spotify', 'etc', 'https://t.co/23yy3whBlc', '@grg']  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import data_cleaning as dc\n",
    "import stock_pricing as sp\n",
    "import importlib\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Force reload data_cleaning and stock_pricing\n",
    "importlib.reload(dc)\n",
    "importlib.reload(sp)\n",
    "\n",
    "# Prepare the NLTK resources\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define desired database parameters. Set to -1 to load all data.\n",
    "database_size = -1\n",
    "\n",
    "# Optionally force data to be regenerated\n",
    "force_data_regeneration = False\n",
    "\n",
    "try:\n",
    "    # If force_data_regeneration is set, force an exception to reload the data\n",
    "    if force_data_regeneration:\n",
    "        print('Forcing data regeneration.')\n",
    "        raise ValueError('Forcing data regeneration.')\n",
    "    \n",
    "    # Load the preprocessed data if it exists\n",
    "    df = pd.read_csv('./stockerbot-export-preprocessed.csv')\n",
    "    \n",
    "    # If dataframe is not expected size, reload the data\n",
    "    if database_size != -1 and len(df) > database_size:\n",
    "        df = df.sample(n=database_size)\n",
    "    elif database_size != -1 and len(df) < database_size:    \n",
    "        print('Preprocessed file is not the expected size. Reloading data.')\n",
    "        raise ValueError('Preprocessed file is not the expected size.')\n",
    "    \n",
    "    print('Preprocessed file found and loaded.')\n",
    "except (FileNotFoundError, ValueError):\n",
    "    # Load dataset with stock data\n",
    "    df = sp.preprocess_nasdaq_df(database_size)\n",
    "\n",
    "    # Add sentiment column with TextBlob if it doesn't exist\n",
    "    df['tweet_polarity'] = df['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "    df['tweet_subjectivity'] = df['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "\n",
    "    # Apply preprocessing to the 'tweet' column\n",
    "    df['preprocessed_tweet'] = df['text'].apply(lambda tweet: dc.preprocess_tweet(tweet, lemmatizer))\n",
    "        \n",
    "    # Save the preprocessed data\n",
    "    df.to_csv('./stockerbot-export-preprocessed.csv', index=False)\n",
    "    print('File preprocessing completed and saved.')\n",
    "\n",
    "# Display the preprocessed dataframe\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(f\"Dataframe shape: {df.shape}\")\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# TF-IDF vectorization for the 'preprocessed_tweet' column\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['preprocessed_tweet'].astype('U'))  # Convert to Unicode\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "onehot_encoder = OneHotEncoder()\n",
    "categorical_features = onehot_encoder.fit_transform(df[['source', 'symbols']])\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "sentiment_features = scaler.fit_transform(df[['tweet_polarity', 'tweet_subjectivity']])\n",
    "price_features = scaler.fit_transform(df[['Price Day Before Tweet', 'Price Day of Tweet']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing/Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Combine all features into a single matrix\n",
    "X = hstack([tfidf_features, categorical_features, sentiment_features, price_features])\n",
    "\n",
    "# The target variable\n",
    "y = df['Price Day After Tweet'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31523.144250045912, tolerance: 18237.025626235943\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31826.058966408935, tolerance: 18722.5635719477\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31869.97442101584, tolerance: 18430.55370234813\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32068.621663098682, tolerance: 18880.882424279967\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32256.67299478928, tolerance: 19314.753951730858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24915.040338090723, tolerance: 18237.025626235943\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25705.832395409434, tolerance: 18722.5635719477\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25396.181389525016, tolerance: 18430.55370234813\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25865.135281033006, tolerance: 18880.882424279967\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27092.379489519866, tolerance: 19314.753951730858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24645.577125362775, tolerance: 18237.025626235943\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25723.049156132132, tolerance: 18722.5635719477\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25497.02591380762, tolerance: 18430.55370234813\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26055.47813440778, tolerance: 18880.882424279967\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26844.802982065154, tolerance: 19314.753951730858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26093.638005448025, tolerance: 18237.025626235943\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26923.340877819137, tolerance: 18722.5635719477\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26585.356722834156, tolerance: 18430.55370234813\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27246.58078590485, tolerance: 18880.882424279967\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28090.999148073723, tolerance: 19314.753951730858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25804.049530844844, tolerance: 18237.025626235943\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26408.80207809789, tolerance: 18722.5635719477\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26367.281150034236, tolerance: 18430.55370234813\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26775.274331380984, tolerance: 18880.882424279967\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27733.416600582685, tolerance: 19314.753951730858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22639.91322434065, tolerance: 18237.025626235943\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21125.770882964134, tolerance: 18722.5635719477\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23591.040689354762, tolerance: 18430.55370234813\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22096.119381981203, tolerance: 18880.882424279967\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/seby/Desktop/School/2024_Spring/cs4400/final_project/myenv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:639: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24025.07953136717, tolerance: 19314.753951730858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Train linear regression model\n",
    "linear_reg_model = LinearRegression()\n",
    "linear_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Train random forest regression model\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Set up hyperparameter grids for optimization\n",
    "ridge_params = {'alpha': np.logspace(-6, 6, 13)}\n",
    "lasso_params = {'alpha': np.logspace(-6, 6, 13)}\n",
    "\n",
    "# Set up Ridge regression model and GridSearchCV\n",
    "ridge_model = Ridge()\n",
    "ridge_grid = GridSearchCV(ridge_model, ridge_params, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "\n",
    "# Set up Lasso regression model and GridSearchCV\n",
    "lasso_model = Lasso()\n",
    "lasso_grid = GridSearchCV(lasso_model, lasso_params, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "\n",
    "# Find the best models\n",
    "ridge_model = ridge_grid.best_estimator_\n",
    "lasso_model = lasso_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Evaluate linear regression model\n",
    "linear_reg_pred = linear_reg_model.predict(X_test)\n",
    "linear_reg_mae = mean_absolute_error(y_test, linear_reg_pred)\n",
    "linear_reg_mse = mean_squared_error(y_test, linear_reg_pred)\n",
    "linear_reg_rmse = mean_squared_error(y_test, linear_reg_pred, squared=False)\n",
    "linear_reg_r2 = r2_score(y_test, linear_reg_pred)\n",
    "\n",
    "# Evaluate random forest regression model\n",
    "random_forest_pred = random_forest_model.predict(X_test)\n",
    "random_forest_mae = mean_absolute_error(y_test, random_forest_pred)\n",
    "random_forest_mse = mean_squared_error(y_test, random_forest_pred)\n",
    "random_forest_rmse = mean_squared_error(y_test, random_forest_pred, squared=False)\n",
    "random_forest_r2 = r2_score(y_test, random_forest_pred)\n",
    "\n",
    "# Evaluate ridge regression model\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "ridge_rmse = mean_squared_error(y_test, ridge_pred, squared=False)\n",
    "ridge_r2 = r2_score(y_test, ridge_pred)\n",
    "\n",
    "# Evaluate lasso regression model\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "lasso_mae = mean_absolute_error(y_test, lasso_pred)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
    "lasso_rmse = mean_squared_error(y_test, lasso_pred, squared=False)\n",
    "lasso_r2 = r2_score(y_test, lasso_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define labels and data for each model\n",
    "models = ['Linear Regression', 'Random Forest', 'Ridge Regression', 'Lasso Regression']\n",
    "mae_scores = [linear_reg_mae, random_forest_mae, ridge_mae, lasso_mae]\n",
    "mse_scores = [linear_reg_mse, random_forest_mse, ridge_mse, lasso_mse]\n",
    "rmse_scores = [linear_reg_rmse, random_forest_rmse, ridge_rmse, lasso_rmse]\n",
    "r2_scores = [linear_reg_r2, random_forest_r2, ridge_r2, lasso_r2]\n",
    "\n",
    "# Plotting MAE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, mae_scores, color='skyblue')\n",
    "plt.title('Mean Absolute Error (MAE) Comparison')\n",
    "plt.xlabel('Regression Model')\n",
    "plt.ylabel('MAE (USD)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, mse_scores, color='salmon')\n",
    "plt.title('Mean Squared Error (MSE) Comparison')\n",
    "plt.xlabel('Regression Model')\n",
    "plt.ylabel('MSE (USD^2)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting RMSE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, rmse_scores, color='lightgreen')\n",
    "plt.title('Root Mean Squared Error (RMSE) Comparison')\n",
    "plt.xlabel('Regression Model')\n",
    "plt.ylabel('RMSE (USD)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting R2\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, r2_scores, color='violet')\n",
    "plt.title('R-Squared (R2) Comparison')\n",
    "plt.xlabel('Regression Model')\n",
    "plt.ylabel('R2')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
