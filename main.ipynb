{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import data_cleaning as dc\n",
    "import preprocess_NASDAQ_data as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FB-GOOGL-GOOG: No data found, symbol may be delisted\n",
      "HRS: No data found, symbol may be delisted\n",
      "INTC-USB: No data found, symbol may be delisted\n",
      "AMZN-GPS: No data found, symbol may be delisted\n",
      "TICKER: No data found, symbol may be delisted\n",
      "CBS: No data found, symbol may be delisted\n",
      "TWTR: No data found, symbol may be delisted\n",
      "FB: No data found, symbol may be delisted\n",
      "INFO: No data found, symbol may be delisted\n",
      "JEC: No data found, symbol may be delisted\n",
      "FNSR: No data found, symbol may be delisted\n",
      "RE: No data found, symbol may be delisted\n",
      "TMK: No data found, symbol may be delisted\n",
      "NUAN: No data found, symbol may be delisted\n",
      "TRQ: No data found, symbol may be delisted\n",
      "DCIX: No data found, symbol may be delisted\n",
      "FBHS: No data found, symbol may be delisted\n",
      "PAH: No price data found, symbol may be delisted (period=10y)\n",
      "WYN: No price data found, symbol may be delisted (period=10y)\n",
      "LUK: No price data found, symbol may be delisted (period=10y)\n",
      "FMSA: No price data found, symbol may be delisted (period=10y)\n",
      "HDS: No data found, symbol may be delisted\n",
      "WLTW: No data found, symbol may be delisted\n",
      "DLPH: No data found, symbol may be delisted\n",
      "GNCA: No data found, symbol may be delisted\n",
      "VAR: No data found, symbol may be delisted\n",
      "XL: No data found, symbol may be delisted\n",
      "MON: No data found, symbol may be delisted\n",
      "XLNX: No data found, symbol may be delisted\n",
      "DISCK: No data found, symbol may be delisted\n",
      "CY: No data found, symbol may be delisted\n",
      "DPS: No price data found, symbol may be delisted (period=10y)\n",
      "XEC: No data found, symbol may be delisted\n",
      "NBL: No data found, symbol may be delisted\n",
      "ABC: No data found, symbol may be delisted\n",
      "AABA: No data found, symbol may be delisted\n",
      "DISCA: No data found, symbol may be delisted\n",
      "VIAB: No data found, symbol may be delisted\n",
      "FEYE: No data found, symbol may be delisted\n",
      "APRN: No data found, symbol may be delisted\n",
      "MNK: No data found, symbol may be delisted\n",
      "LLL: No data found, symbol may be delisted\n",
      "DISH: No data found, symbol may be delisted\n",
      "KSU: No data found, symbol may be delisted\n",
      "SYMC: No data found, symbol may be delisted\n",
      "BBBY: No data found, symbol may be delisted\n",
      "CTXS: No data found, symbol may be delisted\n",
      "ALXN: No data found, symbol may be delisted\n",
      "APC: No data found, symbol may be delisted\n",
      "BHGE: No data found, symbol may be delisted\n",
      "GLUU: No data found, symbol may be delisted\n",
      "CRZO: No data found, symbol may be delisted\n",
      "COG: No data found, symbol may be delisted\n",
      "RHT: No data found, symbol may be delisted\n",
      "ZNGA: No data found, symbol may be delisted\n",
      "AGN: No data found, symbol may be delisted\n",
      "GG: No data found, symbol may be delisted\n",
      "UTX: No data found, symbol may be delisted\n",
      "BBT: No data found, symbol may be delisted\n",
      "MYL: No data found, symbol may be delisted\n",
      "ETFC: No data found, symbol may be delisted\n",
      "VRX: No price data found, symbol may be delisted (period=10y)\n",
      "GGP: No price data found, symbol may be delisted (period=10y)\n",
      "ARNC: No data found, symbol may be delisted\n",
      "SPN: No data found, symbol may be delisted\n",
      "TSS: No data found, symbol may be delisted\n",
      "SRC: No data found, symbol may be delisted\n",
      "ADS: No data found, symbol may be delisted\n",
      "ESV: No data found, symbol may be delisted\n",
      "CXO: No data found, symbol may be delisted\n",
      "AUY: No data found, symbol may be delisted\n",
      "WLL: No data found, symbol may be delisted\n",
      "RTN: No data found, symbol may be delisted\n",
      "OAS: No data found, symbol may be delisted\n",
      "CTL: No data found, symbol may be delisted\n",
      "RAD: No data found, symbol may be delisted\n",
      "WPX: No data found, symbol may be delisted\n",
      "WFT: No data found, symbol may be delisted\n",
      "ABX: No price data found, symbol may be delisted (period=10y)\n",
      "OMG: No price data found, symbol may be delisted (period=10y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>company_names</th>\n",
       "      <th>url</th>\n",
       "      <th>verified</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>Price Day Before Tweet</th>\n",
       "      <th>Price Day of Tweet</th>\n",
       "      <th>Price Day After Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1019696670777503700</td>\n",
       "      <td>VIDEO: “I was in my office. I was minding my o...</td>\n",
       "      <td>2018-07-18 21:33:26</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>GS</td>\n",
       "      <td>The Goldman Sachs</td>\n",
       "      <td>https://twitter.com/i/web/status/1019696670777...</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>202.197418</td>\n",
       "      <td>202.389969</td>\n",
       "      <td>200.98082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1019709091038548000</td>\n",
       "      <td>The price of lumber $LB_F is down 22% since hi...</td>\n",
       "      <td>2018-07-18 22:22:47</td>\n",
       "      <td>StockTwits</td>\n",
       "      <td>M</td>\n",
       "      <td>Macy's</td>\n",
       "      <td>https://twitter.com/i/web/status/1019709091038...</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>29.254164</td>\n",
       "      <td>29.751329</td>\n",
       "      <td>30.745674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1019711413798035500</td>\n",
       "      <td>Who says the American Dream is dead? https://t...</td>\n",
       "      <td>2018-07-18 22:32:01</td>\n",
       "      <td>TheStreet</td>\n",
       "      <td>AIG</td>\n",
       "      <td>American</td>\n",
       "      <td>https://buff.ly/2L3kmc4</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>46.698963</td>\n",
       "      <td>47.057468</td>\n",
       "      <td>45.964905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1019716662587740200</td>\n",
       "      <td>Barry Silbert is extremely optimistic on bitco...</td>\n",
       "      <td>2018-07-18 22:52:52</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>BTC</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>https://twitter.com/i/web/status/1019716662587...</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>N/A</td>\n",
       "      <td>47.057468</td>\n",
       "      <td>45.964905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1019718460287389700</td>\n",
       "      <td>How satellites avoid attacks and space junk wh...</td>\n",
       "      <td>2018-07-18 23:00:01</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>http://on.forbes.com/6013DqDDU</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>44.699886</td>\n",
       "      <td>44.462238</td>\n",
       "      <td>44.279404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1019696670777503700  VIDEO: “I was in my office. I was minding my o...   \n",
       "1  1019709091038548000  The price of lumber $LB_F is down 22% since hi...   \n",
       "2  1019711413798035500  Who says the American Dream is dead? https://t...   \n",
       "3  1019716662587740200  Barry Silbert is extremely optimistic on bitco...   \n",
       "4  1019718460287389700  How satellites avoid attacks and space junk wh...   \n",
       "\n",
       "            timestamp        source symbols      company_names  \\\n",
       "0 2018-07-18 21:33:26  GoldmanSachs      GS  The Goldman Sachs   \n",
       "1 2018-07-18 22:22:47    StockTwits       M             Macy's   \n",
       "2 2018-07-18 22:32:01     TheStreet     AIG           American   \n",
       "3 2018-07-18 22:52:52   MarketWatch     BTC            Bitcoin   \n",
       "4 2018-07-18 23:00:01        Forbes    ORCL             Oracle   \n",
       "\n",
       "                                                 url  verified  month  day  \\\n",
       "0  https://twitter.com/i/web/status/1019696670777...      True      7   18   \n",
       "1  https://twitter.com/i/web/status/1019709091038...      True      7   18   \n",
       "2                            https://buff.ly/2L3kmc4      True      7   18   \n",
       "3  https://twitter.com/i/web/status/1019716662587...      True      7   18   \n",
       "4                     http://on.forbes.com/6013DqDDU      True      7   18   \n",
       "\n",
       "   year Price Day Before Tweet Price Day of Tweet Price Day After Tweet  \n",
       "0  2018             202.197418         202.389969             200.98082  \n",
       "1  2018              29.254164          29.751329             30.745674  \n",
       "2  2018              46.698963          47.057468             45.964905  \n",
       "3  2018                    N/A          47.057468             45.964905  \n",
       "4  2018              44.699886          44.462238             44.279404  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NASDAQ_price = pre.create_df()\n",
    "NASDAQ_price.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('./stockerbot-export-preprocessed.csv', on_bad_lines='skip')\n",
    "\n",
    "# Prepare the NLTK resources\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Tracks if we did any preprocessing\n",
    "preprocessed = False\n",
    "\n",
    "# Add sentiment column with TextBlob if it doesn't exist\n",
    "if 'tweet_polarity' not in df.columns:\n",
    "    print('Calculating sentiment column...')\n",
    "    df['tweet_polarity'] = df['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "    preprocessed = True\n",
    "if 'tweet_subjectivity' not in df.columns:\n",
    "    print('Calculating subjectivity column...')\n",
    "    df['tweet_subjectivity'] = df['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "    preprocessed = True\n",
    "\n",
    "# Apply preprocessing to the 'text' column if it doesn't exist\n",
    "if 'preprocessed_tweet' not in df.columns:\n",
    "    print('Preprocessing text column...')\n",
    "    df['preprocessed_tweet'] = df['text'].apply(lambda tweet: dc.preprocess_tweet(tweet, lemmatizer))\n",
    "    preprocessed = True\n",
    "    \n",
    "# INSERT STOCK DATA HERE\n",
    "NASDAQ_price = pre.result_df\n",
    "merged_df = pd.merge(NASDAQ_price, df, on='id', how='inner')\n",
    "merged_df.to_csv('./merged-stock-data.csv')\n",
    "\n",
    "display(merged_df.head(20))\n",
    "    \n",
    "# Save the preprocessed data\n",
    "#if preprocessed:\n",
    "    #print('Saving preprocessed data...')\n",
    "    #df.to_csv('./stockerbot-export-preprocessed.csv', index=False)\n",
    "\n",
    "# Display the preprocessed text\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "#display(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NASDAQ_price = pre.result_df\n",
    "NASDAQ_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# TF-IDF vectorization for the 'preprocessed_tweet' column\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['preprocessed_tweet'].astype('U'))  # Convert to Unicode\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_features_source = onehot_encoder.fit_transform(df[['source']])\n",
    "onehot_features_symbols = onehot_encoder.fit_transform(df[['symbols']])\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df[['tweet_polarity', 'tweet_subjectivity']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing/Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Combine all features into a single matrix\n",
    "X = hstack([tfidf_features, onehot_features_source, onehot_features_symbols, scaled_features])\n",
    "\n",
    "# The target variable\n",
    "y = df['price_day_after'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train linear regression model\n",
    "linear_reg_model = LinearRegression()\n",
    "linear_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Train random forest regression model\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Train ridge regression model\n",
    "# Can potentially adjust alpha, maybe try different values\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Train lasso regression model\n",
    "# Can potentially adjust alpha, maybe try different values\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate linear regression model\n",
    "linear_reg_pred = linear_reg_model.predict(X_test)\n",
    "linear_reg_mae = mean_absolute_error(y_test, linear_reg_pred)\n",
    "linear_reg_mse = mean_squared_error(y_test, linear_reg_pred)\n",
    "linear_reg_rmse = mean_squared_error(y_test, linear_reg_pred, squared=False)\n",
    "\n",
    "# Evaluate random forest regression model\n",
    "random_forest_pred = random_forest_model.predict(X_test)\n",
    "random_forest_mae = mean_absolute_error(y_test, random_forest_pred)\n",
    "random_forest_mse = mean_squared_error(y_test, random_forest_pred)\n",
    "random_forest_rmse = mean_squared_error(y_test, random_forest_pred, squared=False)\n",
    "\n",
    "# Evaluate ridge regression model\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "ridge_rmse = mean_squared_error(y_test, ridge_pred, squared=False)\n",
    "\n",
    "# Evaluate lasso regression model\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "lasso_mae = mean_absolute_error(y_test, lasso_pred)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
    "lasso_rmse = mean_squared_error(y_test, lasso_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define labels and data for each model\n",
    "models = ['Linear Regression', 'Random Forest', 'Ridge Regression', 'Lasso Regression']\n",
    "mae_scores = [linear_reg_mae, random_forest_mae, ridge_mae, lasso_mae]\n",
    "mse_scores = [linear_reg_mse, random_forest_mse, ridge_mse, lasso_mse]\n",
    "rmse_scores = [linear_reg_rmse, random_forest_rmse, ridge_rmse, lasso_rmse]\n",
    "\n",
    "# Plotting MAE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, mae_scores, color='skyblue')\n",
    "plt.title('Mean Absolute Error (MAE) Comparison')\n",
    "plt.xlabel('Regression Model')\n",
    "plt.ylabel('MAE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, mse_scores, color='salmon')\n",
    "plt.title('Mean Squared Error (MSE) Comparison')\n",
    "plt.xlabel('Regression Model')\n",
    "plt.ylabel('MSE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting RMSE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, rmse_scores, color='lightgreen')\n",
    "plt.title('Root Mean Squared Error (RMSE) Comparison')\n",
    "plt.xlabel('Regression Model')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
